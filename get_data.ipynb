{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ""
    }
   ],
   "source": [
    "import requests\n",
    "from collections import namedtuple\n",
    "# import validators\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from halo import Halo\n",
    "def get_soup(url):\n",
    "    '''\n",
    "    Returns a BeautifulSoup version of a web page.\n",
    "    '''\n",
    "    response = requests.get(url)\n",
    "    content = response.text\n",
    "    return BeautifulSoup(content)\n",
    "\n",
    "def get_links(table):\n",
    "    '''\n",
    "    Retrieves links from an embedded tabular structure.\n",
    "    '''\n",
    "    links = set()\n",
    "    for child in table.children:\n",
    "        for link in child.find_all('a', href=True):\n",
    "            links.add(link['href'])\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "⠋ Fetching article list . . .⠙ Fetching article list . . .⠹ Fetching article list . . .⠸ Fetching article list . . .⠼ Fetching article list . . .⠴ Fetching article list . . .✔ Fetching list ===> Done\n⠙ Processing articles . . ."
    }
   ],
   "source": [
    "url = 'http://christmas-specials.wikia.com/'\n",
    "    #data='xmas'\n",
    "    # if not validators.url(url):\n",
    "    #     print('Invalid URL')\n",
    "    # path = pathlib.Path(data)\n",
    "\n",
    "spinner = Halo(text='Fetching article list . . .')\n",
    "spinner.start()\n",
    "    \n",
    "soup = get_soup(url + '/wiki/Special:AllPages')\n",
    "spinner.succeed(text='Fetching list ===> Done')\n",
    "\n",
    "'''Process the articles'''\n",
    "\n",
    "articles = set()\n",
    "\n",
    "spinner = Halo(text='Processing articles . . .')\n",
    "spinner.start()\n",
    "\n",
    "table_chunks = soup.find('table', \n",
    "        {'class': ['allpageslist', 'mw-allpages-table-chunk']})\n",
    "    \n",
    "chunks = set(get_links(table_chunks))\n",
    "\n",
    "chunks_done = 0\n",
    "chunks_left = len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ""
    }
   ],
   "source": [
    "# proof of concept\n",
    "\n",
    "article = '/wiki/Mr._Monk_and_the_Man_Who_Shot_Santa_Claus'\n",
    "\n",
    "def get_article_data(article, url='http://christmas-specials.wikia.com/'):\n",
    "    Article = namedtuple('Article', 'title contents categories')\n",
    "    article_soup = get_soup(url + article)\n",
    "    article_title = article_soup.find('h1').contents\n",
    "    article_contents = article_soup.find_all('div', {'class': ['mw-content-ltr', 'mw-content-text', 'mw-collapsible', 'mw-made-collapsible']})\n",
    "    article_categories = article_soup.find_all('li', {'class': 'category normal', 'data-type': 'normal'})\n",
    "    article = Article(title=article_title, contents=article_contents, categories=article_categories)\n",
    "    return article\n",
    "\n",
    "monk = get_article_data(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<li class=\"category normal\" data-name=\"Episodes\" data-namespace=\"\" data-outertag=\"\" data-sortkey=\"\" data-type=\"normal\">\n <span class=\"name\"><a href=\"/wiki/Category:Episodes\" title=\"Category:Episodes\">Episodes</a></span>\n <ul class=\"toolbar\">\n <li class=\"tool editCategory sprite-small edit\" title=\"\"></li>\n <li class=\"tool removeCategory sprite-small delete\" title=\"\"></li>\n </ul>\n </li>,\n <li class=\"category normal\" data-name=\"Originally aired on the USA Network\" data-namespace=\"\" data-outertag=\"\" data-sortkey=\"\" data-type=\"normal\">\n <span class=\"name\"><a href=\"/wiki/Category:Originally_aired_on_the_USA_Network\" title=\"Category:Originally aired on the USA Network\">Originally aired on the USA Network</a></span>\n <ul class=\"toolbar\">\n <li class=\"tool editCategory sprite-small edit\" title=\"\"></li>\n <li class=\"tool removeCategory sprite-small delete\" title=\"\"></li>\n </ul>\n </li>,\n <li class=\"category normal\" data-name=\"2007 releases\" data-namespace=\"\" data-outertag=\"\" data-sortkey=\"\" data-type=\"normal\">\n <span class=\"name\"><a href=\"/wiki/Category:2007_releases\" title=\"Category:2007 releases\">2007 releases</a></span>\n <ul class=\"toolbar\">\n <li class=\"tool editCategory sprite-small edit\" title=\"\"></li>\n <li class=\"tool removeCategory sprite-small delete\" title=\"\"></li>\n </ul>\n </li>,\n <li class=\"category normal\" data-name=\"Universal Studios\" data-namespace=\"\" data-outertag=\"\" data-sortkey=\"\" data-type=\"normal\">\n <span class=\"name\"><a href=\"/wiki/Category:Universal_Studios\" title=\"Category:Universal Studios\">Universal Studios</a></span>\n <ul class=\"toolbar\">\n <li class=\"tool editCategory sprite-small edit\" title=\"\"></li>\n <li class=\"tool removeCategory sprite-small delete\" title=\"\"></li>\n </ul>\n </li>,\n <li class=\"category normal\" data-name=\"ABC Studios\" data-namespace=\"\" data-outertag=\"\" data-sortkey=\"\" data-type=\"normal\">\n <span class=\"name\"><a href=\"/wiki/Category:ABC_Studios\" title=\"Category:ABC Studios\">ABC Studios</a></span>\n <ul class=\"toolbar\">\n <li class=\"tool editCategory sprite-small edit\" title=\"\"></li>\n <li class=\"tool removeCategory sprite-small delete\" title=\"\"></li>\n </ul>\n </li>]"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ""
    }
   ],
   "source": [
    "monk.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "✔ Processing chunks ===> Done\n"
    },
    {
     "data": {
      "text/plain": "<halo.halo.Halo at 0x1092c4fa0>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spinner.text = f'Processing chunks: {chunks_done}/{chunks_left}'\n",
    "\n",
    "'''Process the chunks'''\n",
    "while len(chunks) > 0:\n",
    "    current_link = chunks.pop()\n",
    "    soup = get_soup(url + current_link)\n",
    "    current_table = soup.find('table', \n",
    "    {'class': ['allpageslist', 'mw-allpages-table-chunk']})\n",
    "    if 'allpageslist' in current_table.get('class'):\n",
    "        child_chunks = get_links(current_table)\n",
    "        chunks = chunks.union(child_chunks)\n",
    "        chunks_left += len(child_chunks)\n",
    "    if 'mw-allpages-table-chunk' in current_table.get('class'):\n",
    "        for child in current_table.children:\n",
    "            if isinstance(child, NavigableString):\n",
    "                continue\n",
    "            else:\n",
    "                for link in child.find_all('a', href=True):\n",
    "                    article_link = link['href']\n",
    "                    article = article_link.split('/')[-1]\n",
    "                    articles.add((article, article.replace('_', ' ')))\n",
    "      \n",
    "    chunks_done += 1\n",
    "    spinner.text = f'Processing chunks: {chunks_done}/{chunks_left}'\n",
    "\n",
    "spinner.succeed(text='Processing chunks ===> Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8684"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ""
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "⠋ Printing 8684 articles⠙ Printing 8684 articles✔ Printing 8684 articles. ===> Done\n"
    },
    {
     "data": {
      "text/plain": "<halo.halo.Halo at 0x10a5c2940>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spinner = Halo(text=f'Printing {len(articles)} articles')\n",
    "spinner.start()\n",
    "\n",
    "# for article in sorted(articles):\n",
    "#    with open(f'{article}.txt', 'w') as outfile:\n",
    "#        outfile.write(article)\n",
    "#        outfile.write('\\n')\n",
    "\n",
    "spinner.succeed(text=f'Printing {len(articles)} articles. ===> Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}